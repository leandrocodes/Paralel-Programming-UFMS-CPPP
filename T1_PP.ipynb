{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T1 - PP",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leandrocodes/Paralel-Programming-UFMS-CPPP/blob/master/T1_PP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sx6wbyTZ1T1",
        "colab_type": "code",
        "outputId": "0f21c6d1-0314-46eb-e587-6ae271a040ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-x5wr0cnk\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-x5wr0cnk\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=6ac0f63c3d9ead5a0996db68000e8a9f8dc6d7b9f95e3f1ee6c04714589aa74f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jcmiywti/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg01OMRbZ_nR",
        "colab_type": "code",
        "outputId": "46f41fb5-f5e8-4bca-fb99-4c57055aae7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=ca6a1d8e32ec963643a209820c354531008fd9f897839a3f89e15da328c44aec\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVcP0DmVaD5D",
        "colab_type": "code",
        "outputId": "16da3a35-34c2-4244-a02e-89d42051b9c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "print(\"GPU Name:\",gpu.name)\n",
        "print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Name: Tesla T4\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ovKkKVJaXvV",
        "colab_type": "code",
        "outputId": "9550d628-5874-43e4-8bcc-302c660c10bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLLBw8IHcjAQ",
        "colab_type": "code",
        "outputId": "27b96824-8c79-4465-9da5-7658cbcd90e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <stdio.h>\n",
        "#include <numeric>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "/* Função e constante para mensurar o tempo de execução na GPU */\n",
        "static void CheckCudaErrorAux (const char *, unsigned, const char *, cudaError_t);\n",
        "#define CUDA_CHECK_RETURN(value) CheckCudaErrorAux(__FILE__,__LINE__, #value, value)\n",
        "\n",
        "/* Constante para definir o tamanho do vetor*/\n",
        "#define TAMANHO 32\n",
        "\n",
        "__global__ void MatAdd (float* A, float* B, int N){\n",
        "\n",
        "\tint index = threadIdx.x;\n",
        "\tif (index < TAMANHO){\n",
        "\t\tB[index] = A[index] * 3.1415;\n",
        "\t}\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "\t/*Define o tamanho do vetor*/\n",
        "\tint N = TAMANHO;\n",
        "\tint size = N * sizeof(float);\n",
        "    printf(\"sizeof(float): %u\\n\",sizeof(float));\n",
        "    printf(\"Tamanho em memória alocado para a variável size: %i\\n\",size);  \n",
        "    \n",
        "    /*Define e inicializa o vetor no HOST(CPU)*/\n",
        "\tfloat* h_A = (float *)malloc(size);\n",
        "\tfloat* h_B = (float *)malloc(size);\n",
        "\n",
        "\tfor (int i = 0; i < N; i++){\n",
        "\t\th_A[i] = i;\n",
        "\t\th_B[i] = 0;\n",
        "\t}\n",
        "\n",
        "    /*Define e inicializa o vetor no DEVICE(GPU)*/\n",
        "\tfloat* d_A;\n",
        "\tfloat* d_B;\n",
        "\tcudaMalloc((void **)&d_A, size);\n",
        "\tcudaMalloc((void **)&d_B, size);\n",
        "\n",
        "    /*Copia o vetor do HOST para o DEVICE*/\n",
        "\tcudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    /* Essa porção do código, é a parte que irá mensurar o tempo de execução da soma na GPU,\n",
        "    logo, não se preocupem em aprender, ou caso acharem muito estranho, simplesmente copiem e colem \n",
        "    essa parte, sempre que precisarem calcular o tempo de execução de um kernel na GPU, notem que\n",
        "    essa parte é idêntica ao dos códigos disponibilizados anteriormente*/\n",
        "    \n",
        "    cudaEvent_t start, stop;\n",
        "\tCUDA_CHECK_RETURN(cudaEventCreate(&start));\n",
        "\tCUDA_CHECK_RETURN(cudaEventCreate(&stop));\n",
        "\tfloat gpu_time = 0.0f;\n",
        "\n",
        "    CUDA_CHECK_RETURN(cudaEventRecord(start, 0));  \n",
        "    \n",
        "    /* Realiza a chamada do kernel - MUITO IMPORTANTE*/       \n",
        "\tMatAdd<<<2, 32>>>(d_A, d_B, N);\n",
        "        \n",
        "    CUDA_CHECK_RETURN(cudaEventRecord(stop, 0));\n",
        "    CUDA_CHECK_RETURN(cudaEventSynchronize(stop)); \n",
        "    CUDA_CHECK_RETURN(cudaEventElapsedTime(&gpu_time, start, stop));\n",
        "    \n",
        "    /* A função cudaDeviceSynchronize() sincroniza os dados - MUITO IMPORTANTE*/ \n",
        "    CUDA_CHECK_RETURN(cudaDeviceSynchronize());\n",
        "    \n",
        "\tprintf(\"Tempo de Execução na GPU: %.4f ms \\n\\n\", gpu_time);  \n",
        "    /* FIM DO CÓDIGO QUE MENSURA O TEMPO DE EXECUÇÃO*/\n",
        "      \n",
        "    /* Copia o resultado do vetor do DEVICE para o HOST*/\n",
        "\tcudaMemcpy(h_B, d_B, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    /* Limpa a memória no DEVICE*/\n",
        "\tcudaFree(d_A);\n",
        "\tcudaFree(d_B);\n",
        "\n",
        "    /* Imprime o resultado*/\n",
        "    printf(\"A[] = \");\n",
        "    for (int i = 0; i < N; i++){\n",
        "        if (i == 0) printf(\"[\");\n",
        "        printf(\"%.0f\",h_A[i]);        \n",
        "        if (i == N-1) printf(\"]\\n\\n\");       \n",
        "        else printf(\", \");\n",
        "    }\n",
        "    printf(\"B[] = \");\n",
        "    for (int i = 0; i < N; i++){\n",
        "        if (i == 0) printf(\"[\");\n",
        "        printf(\"%.4f\",h_B[i]);\n",
        "        if (i == N-1) printf(\"]\\n\\n\");  \n",
        "        else printf(\", \");\n",
        "    }\n",
        "\n",
        "\treturn 0;\n",
        "}\n",
        "\n",
        "\n",
        "/* Verifica o valor de retorno da chamada da API de tempo de execução CUDA e para o programa se a chamada falhar.*/\n",
        "\n",
        "static void CheckCudaErrorAux (const char *file, unsigned line, const char *statement, cudaError_t err){\n",
        "\tif (err == cudaSuccess) return;\n",
        "\tstd::cerr << statement<<\" returned \" << cudaGetErrorString(err) << \"(\"<<err<< \") at \"<<file<<\":\"<<line << std::endl;\n",
        "\texit (1);\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sizeof(float): 4\n",
            "Tamanho em memória alocado para a variável size: 128\n",
            "Tempo de Execução na GPU: 0.0381 ms \n",
            "\n",
            "A[] = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
            "\n",
            "B[] = [0.0000, 3.1415, 6.2830, 9.4245, 12.5660, 15.7075, 18.8490, 21.9905, 25.1320, 28.2735, 31.4150, 34.5565, 37.6980, 40.8395, 43.9810, 47.1225, 50.2640, 53.4055, 56.5470, 59.6885, 62.8300, 65.9715, 69.1130, 72.2545, 75.3960, 78.5375, 81.6790, 84.8205, 87.9620, 91.1035, 94.2450, 97.3865]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na9A9IsfithD",
        "colab_type": "code",
        "outputId": "23278a2f-eabd-4447-a573-b16ec9016c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <time.h>\n",
        "#include <unistd.h>\n",
        "#define N 4096\n",
        "int main(){\n",
        "    long int a[N];\n",
        "    long int b[N];\n",
        "    float pi = 3.1415;\n",
        "\n",
        "\n",
        "    double time = 0.0;\n",
        "\n",
        "    for (long int i = 0; i < N; i++){\n",
        "        a[i] = i;   \n",
        "        b[i] = 0;\n",
        "    }\n",
        "\n",
        "    clock_t begin = clock();\n",
        "    for (long int i = 0; i < N; i++){\n",
        "        b[i] = a[i] * pi;\n",
        "    }\n",
        "\n",
        "    clock_t end = clock();\n",
        "    time += (double)(end - begin) / CLOCKS_PER_SEC;\n",
        "\n",
        "\tprintf(\"Tempo gasto: %f ms\", time*1000);\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tempo gasto: 0.011000 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1S8xPOWi2lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}