# -*- coding: utf-8 -*-
"""T1 - PP

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XpcC3ogrlf2nor7kw711I2qy646p9Wc1
"""

!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git

!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi
!pip install gputil

import GPUtil as GPU
GPUs = GPU.getGPUs()
# XXX: only one GPU on Colab and isn’t guaranteed
gpu = GPUs[0]
print("GPU Name:",gpu.name)
print("GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))

# Commented out IPython magic to ensure Python compatibility.
# %load_ext nvcc_plugin

# Commented out IPython magic to ensure Python compatibility.
# %%cu
# #include <iostream>
# #include <stdio.h>
# #include <numeric>
# #include <stdlib.h>
# #include <cuda.h>
# 
# /* Função e constante para mensurar o tempo de execução na GPU */
# static void CheckCudaErrorAux (const char *, unsigned, const char *, cudaError_t);
# #define CUDA_CHECK_RETURN(value) CheckCudaErrorAux(__FILE__,__LINE__, #value, value)
# 
# /* Constante para definir o tamanho do vetor*/
# #define TAMANHO 32
# 
# __global__ void MatAdd (float* A, float* B, int N){
# 
# 	int index = threadIdx.x;
# 	if (index < TAMANHO){
# 		B[index] = A[index] * 3.1415;
# 	}
# }
# 
# int main(){
# 
# 	/*Define o tamanho do vetor*/
# 	int N = TAMANHO;
# 	int size = N * sizeof(float);
#     printf("sizeof(float): %u\n",sizeof(float));
#     printf("Tamanho em memória alocado para a variável size: %i\n",size);  
#     
#     /*Define e inicializa o vetor no HOST(CPU)*/
# 	float* h_A = (float *)malloc(size);
# 	float* h_B = (float *)malloc(size);
# 
# 	for (int i = 0; i < N; i++){
# 		h_A[i] = i;
# 		h_B[i] = 0;
# 	}
# 
#     /*Define e inicializa o vetor no DEVICE(GPU)*/
# 	float* d_A;
# 	float* d_B;
# 	cudaMalloc((void **)&d_A, size);
# 	cudaMalloc((void **)&d_B, size);
# 
#     /*Copia o vetor do HOST para o DEVICE*/
# 	cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);
# 	cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);
# 
# 
# 
#     
#     /* Essa porção do código, é a parte que irá mensurar o tempo de execução da soma na GPU,
#     logo, não se preocupem em aprender, ou caso acharem muito estranho, simplesmente copiem e colem 
#     essa parte, sempre que precisarem calcular o tempo de execução de um kernel na GPU, notem que
#     essa parte é idêntica ao dos códigos disponibilizados anteriormente*/
#     
#     cudaEvent_t start, stop;
# 	CUDA_CHECK_RETURN(cudaEventCreate(&start));
# 	CUDA_CHECK_RETURN(cudaEventCreate(&stop));
# 	float gpu_time = 0.0f;
# 
#     CUDA_CHECK_RETURN(cudaEventRecord(start, 0));  
#     
#     /* Realiza a chamada do kernel - MUITO IMPORTANTE*/       
# 	MatAdd<<<2, 32>>>(d_A, d_B, N);
#         
#     CUDA_CHECK_RETURN(cudaEventRecord(stop, 0));
#     CUDA_CHECK_RETURN(cudaEventSynchronize(stop)); 
#     CUDA_CHECK_RETURN(cudaEventElapsedTime(&gpu_time, start, stop));
#     
#     /* A função cudaDeviceSynchronize() sincroniza os dados - MUITO IMPORTANTE*/ 
#     CUDA_CHECK_RETURN(cudaDeviceSynchronize());
#     
# 	printf("Tempo de Execução na GPU: %.4f ms \n\n", gpu_time);  
#     /* FIM DO CÓDIGO QUE MENSURA O TEMPO DE EXECUÇÃO*/
#       
#     /* Copia o resultado do vetor do DEVICE para o HOST*/
# 	cudaMemcpy(h_B, d_B, size, cudaMemcpyDeviceToHost);
# 
#     /* Limpa a memória no DEVICE*/
# 	cudaFree(d_A);
# 	cudaFree(d_B);
# 
#     /* Imprime o resultado*/
#     printf("A[] = ");
#     for (int i = 0; i < N; i++){
#         if (i == 0) printf("[");
#         printf("%.0f",h_A[i]);        
#         if (i == N-1) printf("]\n\n");       
#         else printf(", ");
#     }
#     printf("B[] = ");
#     for (int i = 0; i < N; i++){
#         if (i == 0) printf("[");
#         printf("%.4f",h_B[i]);
#         if (i == N-1) printf("]\n\n");  
#         else printf(", ");
#     }
# 
# 	return 0;
# }
# 
# 
# /* Verifica o valor de retorno da chamada da API de tempo de execução CUDA e para o programa se a chamada falhar.*/
# 
# static void CheckCudaErrorAux (const char *file, unsigned line, const char *statement, cudaError_t err){
# 	if (err == cudaSuccess) return;
# 	std::cerr << statement<<" returned " << cudaGetErrorString(err) << "("<<err<< ") at "<<file<<":"<<line << std::endl;
# 	exit (1);
# }

# Commented out IPython magic to ensure Python compatibility.
# %%cu
# #include <stdlib.h>
# #include <stdio.h>
# #include <time.h>
# #include <unistd.h>
# #define N 4096
# int main(){
#     long int a[N];
#     long int b[N];
#     float pi = 3.1415;
# 
# 
#     double time = 0.0;
# 
#     for (long int i = 0; i < N; i++){
#         a[i] = i;   
#         b[i] = 0;
#     }
# 
#     clock_t begin = clock();
#     for (long int i = 0; i < N; i++){
#         b[i] = a[i] * pi;
#     }
# 
#     clock_t end = clock();
#     time += (double)(end - begin) / CLOCKS_PER_SEC;
# 
# 	printf("Tempo gasto: %f ms", time*1000);
# }

